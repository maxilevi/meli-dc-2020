{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import helpers\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import collections\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "FACTORS = 100\n",
    "EPOCHS = 1\n",
    "SEARCH_WEIGHT = 3.0#0.15 / 5\n",
    "KAGGLE = False\n",
    "MODEL_TYPE = 'rankfm'#rankfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions loaded!\n"
     ]
    }
   ],
   "source": [
    "interactions_train = pd.read_csv('./data/interactions_train_cats.csv')\n",
    "if TEST:\n",
    "    interactions_test = pd.read_csv('./data/interactions_test_cats.csv')\n",
    "print(\"Interactions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/domain_map.pickle', 'rb') as f:\n",
    "    domain_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7894"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([domain_map[x] for x in domain_map.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_interactions(df):\n",
    "    new_df = df[pd.notnull(df['item_id'])].copy()\n",
    "    new_df['user_id'] = new_df['user_id'].astype(int)\n",
    "    new_df['item_id'] = new_df['item_id'].astype(int)\n",
    "    sample_weights = np.array([(1 if x != 'search' else SEARCH_WEIGHT) for x in new_df['event_type']])\n",
    "    return new_df[['user_id', 'item_id']], sample_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_candidate_pairs(users, valid_item_ids):\n",
    "    users_column = []\n",
    "    items_column = []\n",
    "    user_lengths = []\n",
    "    i = 0\n",
    "    #candidates = list([domain_map[x] for x in domain_map.keys()])\n",
    "    for u in users:\n",
    "        candidates = get_candidates(u)\n",
    "        items_column += candidates\n",
    "        users_column += [u] * len(candidates)\n",
    "        user_lengths.append((u, len(candidates)))\n",
    "        if i % 100000 == 0:\n",
    "            print(f\"Progress {i}/{len(users)}\")\n",
    "        i += 1\n",
    "    pairs = pd.DataFrame({'user_id': users_column, 'item_id': items_column})\n",
    "    return pairs, users_column, items_column, user_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(user):\n",
    "    items_interacted = event_dict[user] if user in event_dict else set()\n",
    "    return list(items_interacted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recommendations(recommendations_pairs, items_column, user_lengths):\n",
    "    offset = 0\n",
    "    recommendations = {}\n",
    "    for user, user_len in user_lengths:\n",
    "        user_recs = recommendations_pairs[offset:offset+user_len]\n",
    "        ranked_recs = np.argsort(user_recs)[::-1]\n",
    "        top_10 = [x for x in ranked_recs if not np.isnan(user_recs[x])][:1]\n",
    "        recommendations[user] = [items_column[x + offset] for x in top_10]\n",
    "        offset += user_len\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_interactions(i1, i2):\n",
    "    i1c = i1.copy()\n",
    "    i2c = i2.copy()\n",
    "    i2c['user_id'] += i1c.shape[0]\n",
    "    return i1c.append(i2c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 s, sys: 3.88 s, total: 39.6 s\n",
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "users = None\n",
    "interactions = None\n",
    "sample_weights = None\n",
    "user_features = None\n",
    "\n",
    "if TEST:\n",
    "    interactions = (combine_interactions(interactions_train, interactions_test))#shuffle\n",
    "    validation_users = interactions_test.user_id.unique() + interactions_train.shape[0]\n",
    "    all_users = np.concatenate([interactions_train.user_id.unique(), validation_users])\n",
    "else:\n",
    "    interactions = (interactions_train)\n",
    "    validation_users = interactions_train.user_id.unique()\n",
    "    all_users = validation_users\n",
    "\n",
    "user_target_dict = None\n",
    "\n",
    "## Calculate auxiliary data\n",
    "interactions, sample_weights = encode_interactions(interactions)\n",
    "valid_item_ids = set(interactions['item_id'].unique())\n",
    "event_dict = interactions.groupby('user_id')['item_id'].unique().apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RankFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 11999164 interactions...\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 8.58 µs\n",
      "\n",
      "training epoch: 0\n",
      "log likelihood: -3312505.0\n",
      "CPU times: user 1min 19s, sys: 5.17 s, total: 1min 24s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if MODEL_TYPE == 'rankfm':\n",
    "    from rankfm.rankfm import RankFM\n",
    "    \n",
    "    model = RankFM(factors=FACTORS, loss='warp', max_samples=20, alpha=0.01, sigma=0.1, learning_rate=0.10, learning_schedule='invscaling')\n",
    "    \n",
    "    print(f\"Fitting {interactions.shape[0]} interactions...\")\n",
    "    \n",
    "    %time\n",
    "    model.fit(\n",
    "        interactions,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=True,\n",
    "        sample_weight=sample_weights,\n",
    "        #item_features=item_features,\n",
    "        #user_features=user_features\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create item users pairs to feed the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating candidate pairs\n",
      "Processing users 20000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 40000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 60000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 80000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 100000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 120000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 140000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 160000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 180000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 200000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 220000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 240000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 260000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 280000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 300000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 320000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 340000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 360000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 380000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 400000/413163\n",
      "Progress 0/20000\n",
      "Generating recommnedation pairs\n",
      "Processing users 420000/413163\n",
      "Progress 0/13163\n",
      "Generating recommnedation pairs\n",
      "Mixing recommendations\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generating candidate pairs\")\n",
    "step = 20000\n",
    "\n",
    "recommendation_lists = []\n",
    "for i in range(0, len(validation_users), step):\n",
    "    us = validation_users[i:i+step]\n",
    "    print(f\"Processing users {i+step}/{len(validation_users)}\")\n",
    "    pairs, users_column, items_column, user_lengths = build_candidate_pairs(us, valid_item_ids)\n",
    "    print(f\"Generating recommnedation pairs\")\n",
    "    recommendations_pairs = model.predict(pairs, cold_start='nan')\n",
    "    recommendation_lists.append(\n",
    "        build_recommendations(recommendations_pairs, items_column, user_lengths)\n",
    "    )\n",
    "\n",
    "print(f\"Mixing recommendations\")\n",
    "recommendations = {}\n",
    "for r in recommendation_lists:\n",
    "    recommendations = {**recommendations, **r}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_domain_map = {domain_map[k]: k for k in domain_map.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MLB-RAM_MEMORY_MODULES', 'MLB-WALLETS', 1578, 2118)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "inv_domain_map[recommendations[n][0]], inv_domain_map[user_target_dict[n][0]], recommendations[n][0], user_target_dict[n][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>11</td>\n",
       "      <td>2229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>11</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>11</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>11</td>\n",
       "      <td>4386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>11</td>\n",
       "      <td>4386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>11</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>11</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>11</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>11</td>\n",
       "      <td>1593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>11</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  item_id\n",
       "170       11     2229\n",
       "171       11     1995\n",
       "172       11     1995\n",
       "173       11     4386\n",
       "174       11     4386\n",
       "..       ...      ...\n",
       "296       11     1995\n",
       "297       11     1995\n",
       "298       11     1995\n",
       "299       11     1593\n",
       "300       11     1995\n",
       "\n",
       "[131 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions[interactions['user_id'] == 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring (if training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TEST and not user_target_dict:\n",
    "    user_target_dict = interactions_train.groupby('user_id')['target'].unique().apply(lambda x: x).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26317700278098477\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "for user in recommendations.keys():\n",
    "    if int(recommendations[user][0]) == int(user_target_dict[user]):\n",
    "        score += 1\n",
    "print(score / len(recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "X = np.array([[1, 2], [1, 4], [1, 0],[10, 2], [10, 4], [10, 0]])\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "kmeans.labels_\n",
    "kmeans.predict([[0, 0], [12, 3]])\n",
    "array([1, 0], dtype=int32)\n",
    ">>> kmeans.cluster_centers_\n",
    "array([[10.,  2.],\n",
    "       [ 1.,  2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _relevance(items_dict, item, target):\n",
    "    if item == target:\n",
    "        return 15\n",
    "    if items_dict[item]['domain_id'] == items_dict[target]['domain_id']:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def _get_perfect_dcg():\n",
    "    perfect = [15, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    return sum(perfect[i] / np.log2(i + 2) for i in range(len(perfect))) / len(perfect)\n",
    "\n",
    "def _dcg(items_dict, recommendations, target):\n",
    "    \n",
    "    dcg = sum(_relevance(items_dict, recommendations[i], target) / np.log2(i + 2) for i in range(len(recommendations)))\n",
    "    return dcg / len(recommendations)\n",
    "\n",
    "def ndcg_score(items_dict, recommendations, user_targets_dict):\n",
    "    sum_ndcg = 0\n",
    "    sum_perfect = 0\n",
    "    for x in recommendations.keys():\n",
    "        sum_ndcg += _dcg(items_dict, [int(w) for w in recommendations[x]], int(user_targets_dict[x]))\n",
    "        sum_perfect += _get_perfect_dcg()\n",
    "\n",
    "    return sum_ndcg / sum_perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TEST:\n",
    "    print(ndcg_score(items_dict, recommendations, user_target_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
